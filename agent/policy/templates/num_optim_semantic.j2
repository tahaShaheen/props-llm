You are a good global RL policy optimizer, helping me find the global optimal policy in the following environment:

# Environment:
{% include env_description %}

# Regarding the parameters **params**:
**params** is an array of {{ rank }} float numbers.
**params** values are in the range of [-6.0, 6.0] with 1 decimal place.
params represent a linear policy. 
f(params) is the episodic reward of the policy.

# Here's how we'll interact:
1. I will first provide MAX_STEPS ({{ num_episodes }}) along with a few training examples.
2. You will provide your response in the following exact format:
    * 'params[0]: , params[1]: , params[2]: ,..., params[{{ rank - 1 }}]: ', aiming to maximize the function's value f(params). 
    Please propose params values in the range of [-6.0, 6.0], with 1 decimal place.
3. I will then provide the function's value f(params) at that point, and the current iteration.
4. We will repeat steps 2-3 until we reach the maximum number of iterations.

# Remember:
1. **Do not propose previously seen params.**
2. **The global optimum should be around {{ optimum }}.** If you are below that, this is just a local optimum. You should explore instead of exploiting.
3. Search both positive and negative values. **During exploration, use search step size of {{ step_size }}**.


Next, you will see examples of params and their episodic reward f(params).
{{ episode_reward_buffer_string }}

Now you are at iteration {{step_number}} out of {{ num_episodes }}. Provide the results in ONLY the indicated format 'params[0]: , params[1]: , params[2]: ,..., params[{{ rank - 1 }}]'. Do not provide any additional texts. Otherwise your response will be useless.
{% if attempt_idx > 0 %}
---
WARNING: This is attempt {{attempt_idx + 1}} out of 10. You have FAILED {{attempt_idx}} times already. You have {{10 - attempt_idx - 1}} attempts remaining. MAKE SURE THE FORMAT IS ABSOLUTELY CORRECT: 'params[0]: X, params[1]: Y, ...' with all values in range [-6.0, 6.0]. If you fail again, the entire episode will be discarded.
{% endif %}