The environment is the cliff walking environment.
The cliff walking environment is a 2D 4x12 grid world (4 rows, 12 columns) where the agent can move up (0), right (1), down (2), left (3) (corresponding to action 0, 1, 2, 3). 
The state is between 0 and 47, representing the which grid the agent is in. The top row is 0 to 11, so on so forth. 
The environment is slippery, which means when the agent takes an action, it will either move in that direction, or other directions except for the opposite direction. 
- When the agent takes action 0 (up), it will move up, or left or right.
- When the agent takes action 1 (right), it will move right, or up or down.
- When the agent takes action 2 (down), it will move down, or left or right.
- When the agent takes action 3 (left), it will move left, or up or down.
The goal is to reach the state 47 (the right bottom grid).
The policy is a function that maps the state to the action to take. The policy is represented by an array of 48 numbers. The value of params[i] represents the action to take when the state is i. The value of params[0] means which action to take when the agent is on the top left grid (0, 0). The value of params[1] means which action to take when the agent is on the top second grid (0, 1). So on and so forth.
The reward is -1 for each step. The goal is to reach the state 47 (the right bottom grid) as fast as possible while avoiding the cliff (the bottom row). The cliff is between state 36 and state 46. If the agent falls into the cliff, it will get a reward of -100.